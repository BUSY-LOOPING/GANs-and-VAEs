{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a95fd07-36a4-4e17-a5fc-83179a44958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import util\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f835f97-9843-44cd-8cd8-b56a96a7d3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in and transforming data...\n"
     ]
    }
   ],
   "source": [
    "X, Y = util.get_mnist()\n",
    "N, D = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27defab-e52d-4a3b-96cd-065ee901934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 784)               235984    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 471,484\n",
      "Trainable params: 471,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#input layer is a 2d vector of size N X D\n",
    "M = 300\n",
    "i = Input(D, )\n",
    "\n",
    "#input -> hidden\n",
    "x = Dense(M, activation = 'relu') (i)\n",
    "\n",
    "#hidden -> output\n",
    "x = Dense(D, activation = 'sigmoid') (x)\n",
    "\n",
    "model = Model(i, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4df8502-bf08-4c2f-8457-610667af3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model) :\n",
    "    def __init__ (self, model, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = model\n",
    "        \n",
    "    def compile(self, opt, loss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.opt = opt\n",
    "        self.loss = loss\n",
    "    \n",
    "    def train_step(self, batch, **kwargs):\n",
    "        ##it takes one batch of data and trains on that batch\n",
    "        \n",
    "        X, Y = batch\n",
    "        with tf.GradientTape() as tape :\n",
    "            X_hat = self.model(X, training = True)\n",
    "            print(X_hat)\n",
    "            total_loss = self.loss(Y, X_hat)\n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        \n",
    "        self.opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        \n",
    "        return {'loss': total_loss}\n",
    "    \n",
    "    def test_step(self, batch, **kwargs) :\n",
    "        X, y = batch\n",
    "        X_hat = self.model(X, training = False)\n",
    "\n",
    "        total_loss = self.loss(Y, X_hat)\n",
    "        return {'loss': total_loss}\n",
    "    \n",
    "    def call(self, X, **kwargs) :\n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efad0a1-6041-4868-a0fe-8271385646d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(model)\n",
    "autoencoder.compile(opt=RMSprop(learning_rate=0.001), loss = tf.keras.losses.BinaryCrossentropy())\n",
    "autoencoder.fit(X, X, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0000db4-bbec-4f3a-9f0b-901547f8ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "while not done :\n",
    "    i = np.random.choice(len(X))\n",
    "    x = X[i]\n",
    "    im = model.predict(x.reshape(1, -1)).reshape(28, 28)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(x.reshape(28, 28), cmap = 'gray')\n",
    "    plt.title('Original')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(im, cmap = 'gray')\n",
    "    plt.title('Recostruction')\n",
    "    plt.show()\n",
    "    \n",
    "    ans = input('Generate another?')\n",
    "    if ans and ans[0] in ('n' or 'N') :\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bb1a3-4f40-4b6b-9e13-326e1d50620a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
