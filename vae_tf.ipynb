{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "284fce3a-3788-4497-a9de-6438d73bcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a491042-a1a1-4caf-b63f-e5f54646ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal = tfp.distributions.Normal\n",
    "Bernoulli = tfp.distributions.Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da71f17-d788-49b3-b942-f4bf7c14d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(object) :\n",
    "    def __init__(self, M1, M2, f=tf.nn.relu) :\n",
    "        \n",
    "        self.W = tf.Variable(tf.random.normal(shape=(M1, M2)) * 2 / np.sqrt(M1 * M2))\n",
    "        self.b = tf.Variable(np.zeros(M2).astype(np.float32))\n",
    "        self.f = f\n",
    "        \n",
    "    def forward(self, X) :\n",
    "        return self.f(tf.matmul(X, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e431f8c-b43f-4802-bf57-abcf1f146761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder :\n",
    "    def __init__(self, D, hidden_layer_sizes) :\n",
    "        '''\n",
    "        initializes the params : \n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        D : int\n",
    "            The input data dimension. eg-for a input flattened image of 28x28 , D = 784\n",
    "        \n",
    "        hidden_layer_sizes : list\n",
    "            specifies the size of every layer in the encoder upto the final hidden layer Z. \n",
    "            The decoder will have the reverse shape.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            \n",
    "        '''\n",
    "        #represents the batch of training data\n",
    "        self.X = tf.keras.layers.Input(shape=(D), dtype=tf.float32)\n",
    "        \n",
    "        #encoder\n",
    "        self.encoder_layers = []\n",
    "        M_in = D #initial input data dimension\n",
    "        for M_out in hidden_layer_sizes[:-1] :\n",
    "            h = DenseLayer(M_in, M_out)\n",
    "            self.encoder_layers.append(h)\n",
    "            M_in = M_out\n",
    "        \n",
    "        #for convenience , we will refer to the final encoder size as M\n",
    "        #also the input to the decoder size\n",
    "        \n",
    "        M = hidden_layer_sizes[-1]\n",
    "        # the encoder's final layer output is unbounded\n",
    "        #so there is no activation function\n",
    "        #we also need 2 times as many units as specified by M_out\n",
    "        #since there need to be (M_out x mean) + (M_out x variance)\n",
    "        h = DenseLayer(M_in, M * 2, f = lambda x : x)\n",
    "        self.encoder_layers.append(h)\n",
    "        \n",
    "        \n",
    "        #getting the output of the encoder\n",
    "        #get the mean/std dev of Z\n",
    "        #note that the variance must be > 0\n",
    "        current_layer_value = self.X\n",
    "        for layer in self.encoder_layers :\n",
    "            current_layer_value = layer.forward(current_layer_value)\n",
    "        self.means = current_layer_value[:, :M]\n",
    "        self.stddev = tf.nn.softplus(current_layer_value[:, M:]) + 1e-6 #smoothing factor \n",
    "        #this is added so that we dont get a number too close to 0 causing singularity\n",
    "        \n",
    "        #get a sample of Z\n",
    "        print(f'self.means = {self.means} self.stddev = {self.stddev}')\n",
    "        self.Z = Normal(loc = self.means, scale=self.stddev)\n",
    "        \n",
    "        #decoder\n",
    "        self.decoder_layers = []\n",
    "        M_in = M\n",
    "        for M_out in reversed(hidden_layer_sizes[:-1]):\n",
    "            h = DenseLayer(M_in, M_out)\n",
    "            self.decoder_layers.append(h)\n",
    "            M_in = M_out\n",
    "        \n",
    "        #the final layer will have shape D, i.e. the input dimensionality\n",
    "        \n",
    "        #the activation function for the last layer is nothing as we have fn in tf that will\n",
    "        #accept logits\n",
    "        h = DenseLayer(M_in, D, f = lambda x : x)\n",
    "        self.decoder_layers.append(h)\n",
    "        \n",
    "        #getting the logits\n",
    "        current_layer_value = self.Z\n",
    "        for layer in self.decoder_layers :\n",
    "            current_layer_value = layer.forward(current_layer_value)\n",
    "        logits = current_layer_value\n",
    "        posterior_predictive_logits = logits\n",
    "        \n",
    "        #get the output \n",
    "        self.X_hat_distribution = Bernoulli(logits=logits)\n",
    "        \n",
    "        #take samples from X_hat\n",
    "        #This is called posterior predictive sample\n",
    "        self.posterior_predictive = self.X_hat_distribution.sample()\n",
    "        self.posterior_predictive_prob = tf.nn.sigmoid(logits) #for the mean output image\n",
    "        \n",
    "        #for prior predictive sample\n",
    "        #first draw a sample from Standard Normal of size M, the size of the latent vector\n",
    "        #sampling from a Z ~ N(0, 1)\n",
    "        standard_normal = Normal(\n",
    "            loc = np.zeros(M, dtype = np.float32),\n",
    "            scale= np.ones(M, dtype = np.float32)\n",
    "        )\n",
    "        \n",
    "        Z_std = standard_normal.sample(1)\n",
    "        current_layer_value = Z_std\n",
    "        for layer in self.decoder_layers :\n",
    "            current_layer_value = layer.forward(current_layer_value)\n",
    "        logits = current_layer_value\n",
    "        \n",
    "        #get the output \n",
    "        self.prior_predictive_dist = Bernoulli(logits=logits)\n",
    "        \n",
    "        #take samples from prior_predictive_dist\n",
    "        #This is called prior predictive sample\n",
    "        self.prior_predictive = self.prior_predictive_dist.sample()\n",
    "        self.prior_predictive_prob = tf.nn.sigmoid(logits) #for the mean output image\n",
    "        \n",
    "        #getting the output for the given z\n",
    "        self.Z_input = tf.keras.Input(shape=(None, M), dtype=tf.float32)\n",
    "        current_layer_value = self.Z_input\n",
    "        for layer in self.decoder_layers :\n",
    "            current_layer_value = layer.forward(current_layer_value)\n",
    "        logits = current_layer_value\n",
    "        self.prior_predictive_from_input_probs = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        \n",
    "        #COST\n",
    "        #KL-divergence\n",
    "        kl = tf.reduce_sum(\n",
    "            #or self.Z.kl_divergence(standard_normal)\n",
    "            tfp.distributions.kl_divergence(\n",
    "                self.Z, standard_normal \n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        expected_log_likelihood = tf.reduce_sum(\n",
    "            self.X_hat_distribution.log_prob(self.X),\n",
    "            axis = 1\n",
    "        )\n",
    "        \n",
    "        self.elbo = tf.reduce_sum(expected_log_likelihood - kl)\n",
    "        self.train_op = tf.keras.optimizers.RMSprop(learning_rate=0.001).minimize(self.elbo)\n",
    "        \n",
    "        model = tf.keras.models.Model(self.X)\n",
    "        model.compile(optimizer=self.train_op)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ba3614ae-f739-4e8b-bcc6-c88d6d2cb6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_36), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(784, 200) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_54), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(200,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_37), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(200, 200) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.__operators__.add_55), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(200,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "self.means = KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='tf.__operators__.getitem_36/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_36'\") self.stddev = KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='tf.__operators__.add_56/AddV2:0', description=\"created by layer 'tf.__operators__.add_56'\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TypeError: object of type 'Normal' has no len()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vae \u001b[38;5;241m=\u001b[39m VariationalAutoencoder(\u001b[38;5;241m784\u001b[39m, [\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m100\u001b[39m])\n",
      "Cell \u001b[1;32mIn [51], line 74\u001b[0m, in \u001b[0;36mVariationalAutoencoder.__init__\u001b[1;34m(self, D, hidden_layer_sizes)\u001b[0m\n\u001b[0;32m     72\u001b[0m current_layer_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_layers :\n\u001b[1;32m---> 74\u001b[0m     current_layer_value \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_layer_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m logits \u001b[38;5;241m=\u001b[39m current_layer_value\n\u001b[0;32m     76\u001b[0m posterior_predictive_logits \u001b[38;5;241m=\u001b[39m logits\n",
      "Cell \u001b[1;32mIn [3], line 9\u001b[0m, in \u001b[0;36mDenseLayer.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X) :\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb)\n",
      "File \u001b[1;32m~\\Desktop\\env\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\Desktop\\env\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: TypeError: object of type 'Normal' has no len()\n"
     ]
    }
   ],
   "source": [
    "vae = VariationalAutoencoder(784, [200, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f567ff15-cee4-47a7-8e6e-ff0ae8412dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6180783>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Normal(0, 1).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d80d9b-4d98-4d01-8edc-620675384e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
